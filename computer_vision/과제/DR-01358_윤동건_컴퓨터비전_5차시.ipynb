{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmq_ohyPB_im"
      },
      "source": [
        "# 답안 작성 방법\n",
        "\n",
        "아래 이미지에서 \"더블클릭 또는 Enter키를 눌러 수정\"을 누르신후 해당 창에 답을 적으시면 됩니다.\n",
        "\n",
        "![image](https://github.com/user-attachments/assets/2aa2ff05-fb0e-4f00-a121-78afeaad4f09)\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiAFUXF2DadY"
      },
      "source": [
        "# 05차시 과제"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Logistic Regression이 무엇인지 서술하시오."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "출력이 0과 1로 나뉘는 이진 데이터셋에서 특정 입력에 대한 결과가 1에 수렴할 확률을 예측하는 것."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Logistic Regression을 사용할 수 있는 사례를 5가지만 서술하시오."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "합격여부, 구매여부, 생존여부, 당뇨병, 스팸메일 인지 아닌지"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 제시된 코드에 주석을 작성하고 조건에 맞추어 빈칸(***)를 채워라.\n",
        "\n",
        "**조건**\n",
        "\n",
        "1. Optimizer는 Adam을 사용하라\n",
        "2. learning rate는 0.001을 사용하라\n",
        "3. loss function은 MSE를 사용하라.\n",
        "4. 에포크는 100으로 설정하라."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "model = torch.nn.Linear(2, 1)\n",
        "\n",
        "optim = torch.optim.Adam(model.parameters())\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "x_data = torch.Tensor([[1.0, 1.5], [2.0, 3.0], [2.0, 4.0]])\n",
        "y_data = torch.Tensor([[2.0], [4.0], [6.0]])\n",
        "\n",
        "for epoch in range(100):\n",
        "    y_pred = model(x_data)\n",
        "\n",
        "    loss = criterion(y_pred, y_data)\n",
        "\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 역전파(Back-propagation)이 무엇인지 서술하시오."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "임의의 가중치와 편향으로 게산된 손실함수, 그 손실함수의 기울기를 계산하여 손실을 최소화 하는 방향으로 가중치,편향을 조정한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 아래 제공된 수식은 sigmoid 함수이다. z값이 양의 무한대로 발산할때와 음의 무한대로 발산할 때 각각 sigmoid 값이 어떻게 변하는지 서술하라.\n",
        "\n",
        "\n",
        "$$\n",
        "\n",
        "\\sigma(z) = {1 \\over 1+e^{-z}}\n",
        "\n",
        "$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "향의 무한대 -> 1 , 음의 무한대 -> 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sigmoid 함수의 입력값(z)이 양의 무한대로 발산하거나 음의 무한대로 발산하는 경우 인공지능 모델의 학습에 어떠한 영향을 미치는지 서술하라.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "양단의 무한대로 발산하게 된다면 시그모이드 함수를 거치며 1,0으로 수렴하게 되고 그 기울기는 거의 0이 된다. 이렇게 작은 기울기는 레이어를 거칠 수록 더욱 작아져 결국 가중치가 거의 업데이트 되지 않게된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 아래 제공된 수식은 cross entropy loss에 관한 수식이다. y = [1, 1, 0, 0]이고  $\\hat{y}$은 [1.0, 0.25, 0.875, 0.0]일 때의 loss 값을 구하라.\n",
        "\n",
        "* 아래 수식에서 log의 밑은 2라고 가정한다.\n",
        "$$\n",
        "    loss = - {1 \\over N} log \\hat{y} \\sum_{n=1}^{N}[y_n log\\hat{y}_n + (1- y_n)log (1-\\hat{y}_n)]\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.2500)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# 실제 값과 예측 값 정의\n",
        "y = torch.tensor([1, 1, 0, 0])\n",
        "y_hat = torch.tensor([1.0, 0.25, 0.875, 0.0])\n",
        "\n",
        "# log 계산 시 0이 들어가는 것을 방지하기 위해 작은 값을 더함\n",
        "epsilon = 1e-10\n",
        "\n",
        "# Cross-Entropy Loss 수식 적용\n",
        "loss = -torch.mean(y * torch.log2(y_hat + epsilon) + (1 - y) * torch.log2(1 - y_hat + epsilon))\n",
        "\n",
        "print(loss)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 아래 제공된 두 행렬식의 곱셈 결과를 구하라.\n",
        "\n",
        "$$\n",
        "\n",
        "A = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix}\n",
        "\\qquad\n",
        "B = \\begin{bmatrix} 4 & 3 \\\\ 2 & 1 \\end{bmatrix}\n",
        "$$\n",
        "\n",
        "$$\n",
        "A \\times B = ?\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[8,5],[20,13]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 아래 코드의 output을 확인한 후 행렬곱과 완전 연결 신경망(fully-connected layer)의 관계에 대해 서술하라."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A와 B의 행렬 곱 :  tensor([[ 9.,  5.],\n",
            "        [25., 14.]])\n",
            "A를 linear layer W에 통과시킨 output 값 tensor([[ 9.,  5.],\n",
            "        [25., 14.]], grad_fn=<MmBackward0>)\n",
            "Parameter containing:\n",
            "tensor([[5., 2.],\n",
            "        [3., 1.]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "A = torch.Tensor([[1, 2], [3, 5]])\n",
        "B = torch.Tensor([[5, 3], [2, 1]])\n",
        "print(\"A와 B의 행렬 곱 : \", torch.matmul(A, B))\n",
        "\n",
        "W = linear = torch.nn.Linear(2, 2, bias=False)\n",
        "W.weight = torch.nn.Parameter(B.T)\n",
        "print(\"A를 linear layer W에 통과시킨 output 값\", W(A))\n",
        "print(W.weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### BatchSize와 Epoch이 무엇인지 각각 서술하시오."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "한번의 학습과정에서 사용하는 데이터의 수\n",
        "전체 데이터 셋을 한번 학습한 횟수"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 제공된 조건에 맞추어 아래 코드의 빈칸(***)을 채우고 코드가 오류없이 돌아가는지 확인하시오.\n",
        "\n",
        "**조건**\n",
        "* 모델은 4개의 linear layer로 구성되어 있다.\n",
        "* 각 linear layer의 input과 output은 다음과 같다.\n",
        "    * linear1\n",
        "        * input: 1\n",
        "        * output: 3\n",
        "    * linear2\n",
        "        * input: 3\n",
        "        * output: 5\n",
        "    * linear3\n",
        "        * input: 5\n",
        "        * output: 5\n",
        "    * linear4\n",
        "        * input: 5\n",
        "        * output: 1\n",
        "\n",
        "* model의 layer 구성은 다음과 같다.\n",
        "    * linear1 --> relu --> linear2 --> relu --> linear3 --> relu --> linear4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model(\n",
            "  (linear1): Linear(in_features=1, out_features=3, bias=True)\n",
            "  (linear2): Linear(in_features=3, out_features=5, bias=True)\n",
            "  (linear3): Linear(in_features=5, out_features=5, bias=True)\n",
            "  (linear4): Linear(in_features=5, out_features=1, bias=True)\n",
            "  (relu): ReLU()\n",
            ")\n",
            "tensor([-0.3091], grad_fn=<ViewBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear1 = torch.nn.Linear(1, 3)\n",
        "        self.linear2 = torch.nn.Linear(3, 5)\n",
        "        self.linear3 = torch.nn.Linear(5, 5)\n",
        "        self.linear4 = torch.nn.Linear(5, 1)\n",
        "\n",
        "        self.relu = torch.nn.ReLU()\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.linear1(x))\n",
        "        x = self.relu(self.linear2(x))\n",
        "        x = self.relu(self.linear3(x))\n",
        "        x = self.linear4(x)\n",
        "        return x\n",
        "\n",
        "model = Model()\n",
        "print(model)\n",
        "\n",
        "x = torch.Tensor([1.0])\n",
        "print(model(x))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DataLoader가 무엇이고 왜 필요한지 서술하시오"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "데이터셋을 배치사이즈로 나누어 모델에 공급한다. 데이터를 효율적으로 관리하기 위해 필요하다."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
